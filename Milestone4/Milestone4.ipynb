{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etl2gVvrTaVM",
        "outputId": "6083d2ac-fac1-4d0f-f5b3-2eb0f3862922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# ---------------- PAGE CONFIG ----------------\n",
        "st.set_page_config(\n",
        "    page_title=\"Health Analytics Dashboard\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"üèÉ Health Anomaly Detection Dashboard\")\n",
        "\n",
        "# ---------------- FILE UPLOAD ----------------\n",
        "uploaded_file = st.file_uploader(\n",
        "    \"Upload Fitness Data (CSV)\",\n",
        "    type=[\"csv\"]\n",
        ")\n",
        "\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "\n",
        "    # ---------------- PREPROCESSING ----------------\n",
        "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"timestamp\", \"user_id\"])\n",
        "    df = df.sort_values([\"user_id\", \"timestamp\"])\n",
        "\n",
        "    for col in df.select_dtypes(include=\"number\"):\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "    st.success(\"‚úÖ Data cleaned successfully\")\n",
        "\n",
        "    # ---------------- SIDEBAR FILTERS ----------------\n",
        "    st.sidebar.header(\"üîç Filters\")\n",
        "\n",
        "    user_id = st.sidebar.selectbox(\n",
        "        \"Select User ID\",\n",
        "        df[\"user_id\"].unique()\n",
        "    )\n",
        "\n",
        "    metric = st.sidebar.selectbox(\n",
        "        \"Select Metric\",\n",
        "        [\"heart_rate\", \"sleep\", \"steps\"]\n",
        "    )\n",
        "\n",
        "    user_df = df[df[\"user_id\"] == user_id].copy()\n",
        "    num_records = len(user_df)\n",
        "    st.write(f\"Number of records for selected user: {num_records}\")\n",
        "\n",
        "    # ---------------- DATA CHECK ----------------\n",
        "    if num_records < 30:\n",
        "        st.warning(\n",
        "            \"‚ö†Ô∏è Not enough data for fully reliable anomaly detection (less than 30 records)\"\n",
        "        )\n",
        "\n",
        "    # ---------------- CLUSTERING ----------------\n",
        "    st.subheader(\"üìä Activity Clustering\")\n",
        "\n",
        "    cluster_features = user_df[[\"heart_rate\", \"steps\", \"sleep\"]].fillna(0)\n",
        "    X = StandardScaler().fit_transform(cluster_features)\n",
        "    X_pca = PCA(n_components=2).fit_transform(X)\n",
        "\n",
        "    labels = DBSCAN(eps=1.3, min_samples=5).fit_predict(X_pca)\n",
        "    user_df[\"cluster\"] = labels\n",
        "\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.scatter(\n",
        "        X_pca[:, 0],\n",
        "        X_pca[:, 1],\n",
        "        c=labels,\n",
        "        alpha=0.7\n",
        "    )\n",
        "    ax1.set_xlabel(\"PCA Component 1\")\n",
        "    ax1.set_ylabel(\"PCA Component 2\")\n",
        "    ax1.set_title(\"User Activity Clusters\")\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    # ---------------- ANOMALY DETECTION ----------------\n",
        "    st.subheader(\"üö® Anomaly Detection\")\n",
        "\n",
        "    anomaly_df = user_df[[\"timestamp\", metric]].dropna().copy()\n",
        "\n",
        "    # Dynamically adjust rolling window for small datasets\n",
        "    rolling_window = 5 if num_records >= 5 else max(1, num_records // 2)\n",
        "\n",
        "    # Smoothing\n",
        "    anomaly_df[\"smooth\"] = anomaly_df[metric].rolling(\n",
        "        window=rolling_window, center=True, min_periods=1\n",
        "    ).mean()\n",
        "\n",
        "    mean = anomaly_df[\"smooth\"].mean()\n",
        "    std = anomaly_df[\"smooth\"].std()\n",
        "\n",
        "    anomaly_df[\"anomaly\"] = abs(anomaly_df[\"smooth\"] - mean) > 2.5 * std\n",
        "\n",
        "    # Rule-based alerts\n",
        "    anomaly_df[\"rule_alert\"] = False\n",
        "\n",
        "    if metric == \"heart_rate\":\n",
        "        anomaly_df.loc[\n",
        "            (anomaly_df[metric] < 50) | (anomaly_df[metric] > 110), \"rule_alert\"\n",
        "        ] = True\n",
        "\n",
        "    if metric == \"sleep\":\n",
        "        anomaly_df.loc[\n",
        "            (anomaly_df[metric] < 4) | (anomaly_df[metric] > 10), \"rule_alert\"\n",
        "        ] = True\n",
        "\n",
        "    if metric == \"steps\":\n",
        "        anomaly_df.loc[anomaly_df[metric] < 500, \"rule_alert\"] = True\n",
        "\n",
        "    anomaly_df[\"final_anomaly\"] = anomaly_df[\"anomaly\"] | anomaly_df[\"rule_alert\"]\n",
        "\n",
        "    # ---------------- VISUALIZATION ----------------\n",
        "    fig2, ax2 = plt.subplots(figsize=(14, 6))\n",
        "    ax2.plot(\n",
        "        anomaly_df[\"timestamp\"],\n",
        "        anomaly_df[metric],\n",
        "        label=\"Normal Trend\",\n",
        "        alpha=0.7\n",
        "    )\n",
        "    ax2.scatter(\n",
        "        anomaly_df[anomaly_df[\"final_anomaly\"]][\"timestamp\"],\n",
        "        anomaly_df[anomaly_df[\"final_anomaly\"]][metric],\n",
        "        color=\"red\",\n",
        "        label=\"Anomalies\"\n",
        "    )\n",
        "    ax2.set_title(f\"{metric.replace('_',' ').title()} Trend with Anomalies\")\n",
        "    ax2.set_xlabel(\"Time\")\n",
        "    ax2.set_ylabel(metric.replace(\"_\", \" \").title())\n",
        "    ax2.legend()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    # ---------------- ANOMALY TABLE ----------------\n",
        "    st.subheader(\"üìã Detected Anomalies\")\n",
        "    anomaly_table = anomaly_df[anomaly_df[\"final_anomaly\"]][[\"timestamp\", metric]]\n",
        "    st.dataframe(anomaly_table)\n",
        "\n",
        "    # ---------------- DOWNLOAD REPORT ----------------\n",
        "    csv = anomaly_table.to_csv(index=False).encode(\"utf-8\")\n",
        "    st.download_button(\n",
        "        \"üì• Download Anomaly Report (CSV)\",\n",
        "        csv,\n",
        "        file_name=\"anomaly_report.csv\",\n",
        "        mime=\"text/csv\"\n",
        "    )\n",
        "\n",
        "else:\n",
        "    st.info(\"‚¨ÜÔ∏è Upload a CSV file to start analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok prophet scikit-learn matplotlib pandas numpy --quiet\n",
        "!streamlit run app.py &>/content/streamlit.log &\n"
      ],
      "metadata": {
        "id": "wlX6fXY5TcWQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "print(\"‚úÖ Old ngrok tunnels stopped\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdjJGD1gVhcP",
        "outputId": "91f14b07-7c42-46de-8ad6-86fbde6fc0f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Old ngrok tunnels stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"36ekI5eRqSoX22mhpXU73je9zDP_2gNgSqZFUqsX8w33iLFjk\")\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üöÄ PUBLIC WEBSITE:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA-ktrz-TkOq",
        "outputId": "562cce1c-74cb-44ab-9a68-63a83289bdac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ PUBLIC WEBSITE: NgrokTunnel: \"https://ominous-ela-overbumptious.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ex4kmov3Wf37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z9UfIpckWfzZ"
      }
    }
  ]
}